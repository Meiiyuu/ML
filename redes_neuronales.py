# -*- coding: utf-8 -*-
"""Redes_neuronales.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tMjTLrFqekX8tACz9TOFLooF7J2i50jg

## Proyecto 2: Redes neuronales
Daniela Gil y Sofia Ochoa
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html ///content/Gil_Ochoa.ipynb

"""El objetivo del proyecto es usar una red neuronal para clasificar datos sobre señales de voz, de acuerdo al sentimiento de dicha voz: enojado, triste, feliz.

 Primero importamos las librerias necesarias
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset

"""Importamos como dataframe de pandas al excel que contiene los datos sobre las señales de voz"""

df=pd.read_csv('emotions_by_voice registers.csv')

df

"""El dataset cotiene unicamente datos de tipo númerico que representan parámetros estadísticos que describen la frecuencia de las señales de voz como lo son la media, la desviación estandar, el rango intercuartilico, etc.

Las posibles emociones que describen la señal de voz son 3 (enojado,triste y feliz), las cuales correponden a las 3 categorías de nuestra variable objetivo llamada **label**.

En este caso, como varios de los atributos son parámetros estadísticos entonces no hace falta normalizar las columnas.

Se eliminan las columnas de tipo índice que no aportan información
"""

df = df.drop(columns= ['Unnamed: 0', 'X', 'Unnamed: 0.1'])

"""Creamos los dummies de la variable objetivo, **label**, ya que es una variable categorica, y se convierte cada valor de la celda en una columna diferente de tipo númerica"""

df = pd.get_dummies(df, 'label')

df

"""Creamos los conjuntos de entrenamiento (60%), validación (20%) y test (20%)"""

test= df[546:726]
val= df[726:]
train= df[:546]

"""Ahora definimos la clase 'MyDataset' para convertir los datos de los atributos y la variable objetivo a parejas ordenadas de tensores y así alimentar la red neuronal"""

class MyDataset():

  def __init__(self, df, target_columns):
    y = df.iloc[:, target_columns].values
    X = df.drop(columns=df.columns[target_columns]).values
    self.X = torch.tensor(X, dtype=torch.float32)
    self.y = torch.tensor(y, dtype=torch.float32)

  def __len__(self):
    return len(self.y)

  def __getitem__(self, idx):
    return self.X[idx], self.y[idx]

"""A continuación hacemos uso de la clase MyDataset para convertir cada conjunto definido anteriormente a tensores. En este caso, le mandamos como atributos el respectivo conjunto y la variable objetivo que se subdivide en tres columnas, una por cada categoría"""

train_sec=MyDataset(train,[20, 21, 22])
test_sec=MyDataset(test,[20, 21, 22])
val_sec=MyDataset(val,[20, 21, 22])

"""Ahora definimos los dataloaders para procesar los datos y alimentar a la red neuronal por lotes. Lo hicimos con batch_size = 3"""

train_data=DataLoader(
    train_sec,
    batch_size=3,
    shuffle=False,
 )

test_data=DataLoader(
    test_sec,
    batch_size=3,
    shuffle=False,
 )

val_data=DataLoader(
    val_sec,
    batch_size=3,
    shuffle=False,
 )

"""Se crea la clase Net que define la arquitectura de la red neuronal. Tiene una sola capa oculta con 30 nodos y como función de activación se usó la función sigmoide."""

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(20, 30)
        self.fc2 = nn.Linear(30, 3)

    def forward(self, x):
    	# Do the forward pass
        x = F.sigmoid(self.fc1(x))
        x = self.fc2(x)
        return x

"""Se define el modelo, el optimizador y la función de costo. Se usó un learning rate de 0.1. Como función de costo se usó CrossEntropyLoss ya que es un problema de clasificación y se adapta mejor a este tipo de problemas."""

model=Net()
optimizer=torch.optim.SGD(model.parameters(), lr=0.1)
criterion=nn.CrossEntropyLoss()

"""# Train con 100 epochs

Se define la función para entrenar la red:
"""

def train_model(model,optimizer,loss_module,train_loader,valid_loader,num_epochs):

  valid_loss_min =np.inf  #vamos a encontrar el menor valor de error de validación. Por eso la inicializmaos como 'infinito'

  for i in range(num_epochs):
    model.train()  #ponemos el modelo en modo entrenamiento
    train_loss = 0.0
    v_loss = 0.0

    for data, target in train_loader:
        # se reinician los gradientes
        optimizer.zero_grad()
        # forward pass: calcular la salida para los datos de entrada..
        preds = model(data)
        #print(preds)
        preds = preds.squeeze(dim=1)
        # calculate the batch loss
        loss = loss_module(preds, target)
        # backpropagation: cálculo de gradientes
        loss.backward()
        # actualizar los parámetros
        optimizer.step()
        # actualizar la cuenta de costos a lo largo de los lotes
        train_loss += loss.item()*data.size(0)
    # for data,labels in testloader:
    train_loss = train_loss/len(train_loader.dataset)
    print('train_loss:')
    print(train_loss)

    model.eval() #Ponemos el modelo en modo evaluación.
    #for param in model.parameters():
    #  print(param.data)
    # vamos a evaluar el modelo entrenado, calculando predicciones con el conjunto de validación
    for data,target in valid_loader:
        output=model(data)
        valid_loss= loss_module(output, target)
        valid_loss += loss.item()*data.size(0)
    valid_loss = valid_loss/len(valid_loader.dataset)
    #imprimir estadísticas de entrenamiento y validación
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        i, train_loss, valid_loss))


    #Guardamos el modelo con el menor error de validación.
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save(model.state_dict(), 'proyecto100epoch.pt')
        valid_loss_min = valid_loss

"""Ahora se entrena la red con 100 epochs y se imprime el Training Loss y el Validation Loss."""

train_model(model,optimizer,criterion,train_data,val_data, 100)

"""Ahora, se imprimen los parámetros del mejor modelo"""

for name, param in model.named_parameters():
    if param.requires_grad:
        print (name, param.data)

"""Se imprime el test_loss del mejor modelo"""

test_loss=0.0

criterion= nn.CrossEntropyLoss()
for data, target in test_data:
  output=model(data)
  loss= criterion(output,target)
  test_loss += loss.item()*data.size(0)
test_loss = test_loss/len(test_data.dataset)
print('Test Loss: {:.6f}\n'.format(test_loss))

"""Por último, se evalua el desempeño del modelo mediante la métrica accuracy. Se van a tomar 400 valores aleatorios de todo el dataset  y se calcula la métrica dividiendo el número de predicciones correctas sobre 400."""

data_sec=MyDataset(df,[20, 21, 22])

num_total_predictions=400
num_predicciones_correctas=0
for i in range(num_total_predictions):
  i = random.randrange(1, 905)
  tensor_prediccion = data_sec[i][1]
  tensor_columnas= data_sec[i][0]
  model.eval()
  with torch.no_grad():
    tensor_modelo = model(tensor_columnas)
  if np.argmax(tensor_prediccion)== np.argmax(tensor_modelo):
    num_predicciones_correctas+=1

print("Las predicciones que estan bien son:", num_predicciones_correctas)
print("Total predicciones:", num_total_predictions)
print("Accuracy:", num_predicciones_correctas/num_total_predictions)

"""Se elige un registro del dataset de manera aleatoria y se usa el modelo para predecir el sentimiento."""

registro = random.randrange(1,905)
tensor_prediccion = data_sec[registro][1]
tensor_columnas= data_sec[registro][0]
model.eval()
with torch.no_grad():
    tensor_modelo = model(tensor_columnas)

print(tensor_prediccion)
print(tensor_modelo)

"""Como se ve, la predicción no es correcta, ya que el modelo predice que el sentimiento es angry pero en realidad es happy.

# Variación de hiperparámetros para encontrar el mejor modelo
En esta sección, vamos a variar los hiperparámetros y comparar como cambia el modelo al modificar estos atributos.

Primero, el número de epoch para entrenar el modelo
"""

epochs = [100, 500, 1000, 1500, 2000, 4000, 6000]
loss_test = []
for e in epochs:
  print('Numero de epochs:', e)
  model=Net()
  train_model(model,optimizer,criterion,train_data,val_data, e)
  print('---------------------------------------------')
  test_loss=0.0
  for data, target in test_data:
    output=model(data)
    loss= criterion(output,target)
    test_loss += loss.item()*data.size(0)
  test_loss = test_loss/len(test_data.dataset)
  print('Test Loss: {:.6f}\n'.format(test_loss))
  loss_test.append(format(test_loss))
  print('---------------------------------------------')

"""Se redondea el loss_test para graficar"""

lt = []
for i in loss_test:
  redon= round(float(i),3)
  lt.append(redon)
plt.plot(epochs,lt)
plt.show()

"""Ahora, se varia el learning rate del optimizador para ver como cambia respecto al test loss"""

lr = [0.001, 0.01, 0.1, 1, 5]
loss_test = []
for e in lr:
  print('Learning rate:', e)
  model=Net()
  optimizer=torch.optim.SGD(model.parameters(), lr=e)
  train_model(model,optimizer,criterion,train_data,val_data, 1000)
  print('---------------------------------------------')
  test_loss=0.0
  for data, target in test_data:
    output=model(data)
    loss= criterion(output,target)
    test_loss += loss.item()*data.size(0)
  test_loss = test_loss/len(test_data.dataset)
  print('Test Loss: {:.6f}\n'.format(test_loss))
  loss_test.append(format(test_loss))
  print('---------------------------------------------')

"""De igual manera se aproximan los valores para graficar"""

lt = []
for i in loss_test:
  redon= round(float(i),3)
  lt.append(redon)
plt.plot(lr,lt)
plt.show()

"""De ambas gráficas se puede concluir que se va a tener un menor test loss con un learning rate pequeño y con 1000 epochs. Ahora entrenemos la red de esa manera para ver cuanto cambia el accuracy."""

model=Net()
optimizer=torch.optim.SGD(model.parameters(), lr=0.01)
train_model(model,optimizer,criterion,train_data,val_data, 1000)

data_sec=MyDataset(df,[20, 21, 22])

num_total_predictions=400
num_predicciones_correctas=0
for i in range(num_total_predictions):
  i = random.randrange(1, 905)
  tensor_prediccion = data_sec[i][1]
  tensor_columnas= data_sec[i][0]
  model.eval()
  with torch.no_grad():
    tensor_modelo = model(tensor_columnas)
  if np.argmax(tensor_prediccion)== np.argmax(tensor_modelo):
    num_predicciones_correctas+=1

print("Las predicciones que estan bien son:", num_predicciones_correctas)
print("Total predicciones:", num_total_predictions)
print("Accuracy:", num_predicciones_correctas/num_total_predictions)

"""Como se ve, aumentó el score de accuracy, por lo que este es un modelo más preciso para clasificar los datos."""

registro = random.randrange(1,905)
tensor_prediccion = data_sec[registro][1]
tensor_columnas= data_sec[registro][0]
model.eval()
with torch.no_grad():
    tensor_modelo = model(tensor_columnas)

print(tensor_prediccion)
print(tensor_modelo)

"""Y con una muestra aleatoria, si predijo bien la emoción, sad

# Conclusiones

En cuanto al desempeño del modelo se obtuvo que al experimentar con distintos valores de los parámetros como el learning rate y número de epochs  el modelo se obtienen distintos resultados y la precisión del modelo varía dependiendo de estos valores. Con los diferentes modelos que hicimos, aunque teniamos un test loss no tan alto, no tenemos un acuraccy muy bueno, y en general se puede afirmar que los modelos no son tan buenos para este dataset, y esto se puede deber a los hiperparametros que les pusimos, batch_size, learning rate, las proporciones del train, test y validation, numero de epochs, que pueden no ser los optimos para que no se sobreajuste pero al mismo tiempo prediga bien los datos. Y tambien puede ser por los pocos datos que se tienen, que tengan un patron especifico que la red no pudo entender.
A medida que usabamos mas epoch, el tiempo se aumentaba, por eso no lo hicimos con tantas, pero puede que con mayor numero se obtenga un mejor accuracy, pero al hacer esto se corre el riesgo de sobreajustar el modelo a los datos de entrenamiento y validacion. Es importante aclarar que el test loss y el accuracy son medidas de desempeño diferente, y aunque con muchas epoch se tiene un menor test loss, esto no implica un mayor accuracy, asi que podria evaluarse con mayor numero y obtener un mejor modelo. Con un learning rate alto el modelo aprende patrones especificos de los datos de entrenamiento, por lo que al evaluarlo con el test loss, se obtiene un mayor puntaje.
Se podrian considerar otras medidas de desempeño, como el F1 score, para evaluar los modelos en futuros proyectos.
"""